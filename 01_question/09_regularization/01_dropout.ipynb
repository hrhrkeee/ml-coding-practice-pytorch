{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Dropout\n",
    "\n",
    "Dropoutは、過学習を防ぐための正則化手法です。\n",
    "\n",
    "## Dropout演算\n",
    "\n",
    "訓練時にランダムにニューロンを無効化:\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{1-p} \\cdot m \\odot x\n",
    "$$\n",
    "\n",
    "ここで:\n",
    "- $p$: ドロップ率\n",
    "- $m$: ベルヌーイ分布に従うマスク\n",
    "- $\\odot$: 要素積\n",
    "\n",
    "## 効果\n",
    "\n",
    "- 過学習の抑制\n",
    "- アンサンブル効果\n",
    "- より頑健な特徴の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from notebook_setup import test\n",
    "\n",
    "@test(\"09_regularization.test_01_dropout\", filter_name=\"forward\")\n",
    "def dropout_forward(x: np.ndarray, drop_rate: float = 0.5, training: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Dropoutの順伝播\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x         : np.ndarray - 入力\n",
    "    drop_rate : float - ドロップ率 (0~1)\n",
    "    training  : bool - 訓練モードかどうか\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    \n",
    "    # ここにコードを記述\n",
    "    # ---------------------------------------- #\n",
    "    if training:\n",
    "        # 訓練時: ランダムにドロップしてスケール\n",
    "        mask = np.random.rand(*x.shape) > drop_rate\n",
    "        out = x * mask / (1.0 - drop_rate)\n",
    "    else:\n",
    "        # 推論時: そのまま通す\n",
    "        out = x\n",
    "    # ---------------------------------------- #\n",
    "    \n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
